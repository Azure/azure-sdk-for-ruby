# encoding: utf-8
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.

module Azure::CognitiveServices::Face::V1_0
  #
  # An API for face detection, verification, and identification.
  #
  class Face
    include MsRestAzure

    #
    # Creates and initializes a new instance of the Face class.
    # @param client service class for accessing basic functionality.
    #
    def initialize(client)
      @client = client
    end

    # @return [FaceClient] reference to the FaceClient
    attr_reader :client

    #
    # Given query face's faceId, to search the similar-looking faces from a faceId
    # array, a face list or a large face list. faceId array contains the faces
    # created by [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236),
    # which will expire 24 hours after creation. A "faceListId" is created by
    # [FaceList -
    # Create](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524b)
    # containing persistedFaceIds that will not expire. And a "largeFaceListId" is
    # created by [LargeFaceList -
    # Create](/docs/services/563879b61984550e40cbbe8d/operations/5a157b68d2de3616c086f2cc)
    # containing persistedFaceIds that will also not expire. Depending on the input
    # the returned similar faces list contains faceIds or persistedFaceIds ranked
    # by similarity.
    # <br/>Find similar has two working modes, "matchPerson" and "matchFace".
    # "matchPerson" is the default mode that it tries to find faces of the same
    # person as possible by using internal same-person thresholds. It is useful to
    # find a known person's other photos. Note that an empty list will be returned
    # if no faces pass the internal thresholds. "matchFace" mode ignores
    # same-person thresholds and returns ranked similar faces anyway, even the
    # similarity is low. It can be used in the cases like searching
    # celebrity-looking faces.
    # <br/>The 'recognitionModel' associated with the query face's faceId should be
    # the same as the 'recognitionModel' used by the target faceId array, face list
    # or large face list.
    #
    #
    # @param face_id FaceId of the query face. User needs to call Face - Detect
    # first to get a valid faceId. Note that this faceId is not persisted and will
    # expire 24 hours after the detection call
    # @param face_list_id [String] An existing user-specified unique candidate face
    # list, created in Face List - Create a Face List. Face list contains a set of
    # persistedFaceIds which are persisted and will never expire. Parameter
    # faceListId, largeFaceListId and faceIds should not be provided at the same
    # time.
    # @param large_face_list_id [String] An existing user-specified unique
    # candidate large face list, created in LargeFaceList - Create. Large face list
    # contains a set of persistedFaceIds which are persisted and will never expire.
    # Parameter faceListId, largeFaceListId and faceIds should not be provided at
    # the same time.
    # @param face_ids An array of candidate faceIds. All of them are created by
    # Face - Detect and the faceIds will expire 24 hours after the detection call.
    # The number of faceIds is limited to 1000. Parameter faceListId,
    # largeFaceListId and faceIds should not be provided at the same time.
    # @param max_num_of_candidates_returned [Integer] The number of top similar
    # faces returned. The valid range is [1, 1000].
    # @param mode [FindSimilarMatchMode] Similar face searching mode. It can be
    # "matchPerson" or "matchFace". Possible values include: 'matchPerson',
    # 'matchFace'
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [Array] operation results.
    #
    def find_similar(face_id, face_list_id:nil, large_face_list_id:nil, face_ids:nil, max_num_of_candidates_returned:20, mode:nil, custom_headers:nil)
      response = find_similar_async(face_id, face_list_id:face_list_id, large_face_list_id:large_face_list_id, face_ids:face_ids, max_num_of_candidates_returned:max_num_of_candidates_returned, mode:mode, custom_headers:custom_headers).value!
      response.body unless response.nil?
    end

    #
    # Given query face's faceId, to search the similar-looking faces from a faceId
    # array, a face list or a large face list. faceId array contains the faces
    # created by [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236),
    # which will expire 24 hours after creation. A "faceListId" is created by
    # [FaceList -
    # Create](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524b)
    # containing persistedFaceIds that will not expire. And a "largeFaceListId" is
    # created by [LargeFaceList -
    # Create](/docs/services/563879b61984550e40cbbe8d/operations/5a157b68d2de3616c086f2cc)
    # containing persistedFaceIds that will also not expire. Depending on the input
    # the returned similar faces list contains faceIds or persistedFaceIds ranked
    # by similarity.
    # <br/>Find similar has two working modes, "matchPerson" and "matchFace".
    # "matchPerson" is the default mode that it tries to find faces of the same
    # person as possible by using internal same-person thresholds. It is useful to
    # find a known person's other photos. Note that an empty list will be returned
    # if no faces pass the internal thresholds. "matchFace" mode ignores
    # same-person thresholds and returns ranked similar faces anyway, even the
    # similarity is low. It can be used in the cases like searching
    # celebrity-looking faces.
    # <br/>The 'recognitionModel' associated with the query face's faceId should be
    # the same as the 'recognitionModel' used by the target faceId array, face list
    # or large face list.
    #
    #
    # @param face_id FaceId of the query face. User needs to call Face - Detect
    # first to get a valid faceId. Note that this faceId is not persisted and will
    # expire 24 hours after the detection call
    # @param face_list_id [String] An existing user-specified unique candidate face
    # list, created in Face List - Create a Face List. Face list contains a set of
    # persistedFaceIds which are persisted and will never expire. Parameter
    # faceListId, largeFaceListId and faceIds should not be provided at the same
    # time.
    # @param large_face_list_id [String] An existing user-specified unique
    # candidate large face list, created in LargeFaceList - Create. Large face list
    # contains a set of persistedFaceIds which are persisted and will never expire.
    # Parameter faceListId, largeFaceListId and faceIds should not be provided at
    # the same time.
    # @param face_ids An array of candidate faceIds. All of them are created by
    # Face - Detect and the faceIds will expire 24 hours after the detection call.
    # The number of faceIds is limited to 1000. Parameter faceListId,
    # largeFaceListId and faceIds should not be provided at the same time.
    # @param max_num_of_candidates_returned [Integer] The number of top similar
    # faces returned. The valid range is [1, 1000].
    # @param mode [FindSimilarMatchMode] Similar face searching mode. It can be
    # "matchPerson" or "matchFace". Possible values include: 'matchPerson',
    # 'matchFace'
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [MsRestAzure::AzureOperationResponse] HTTP response information.
    #
    def find_similar_with_http_info(face_id, face_list_id:nil, large_face_list_id:nil, face_ids:nil, max_num_of_candidates_returned:20, mode:nil, custom_headers:nil)
      find_similar_async(face_id, face_list_id:face_list_id, large_face_list_id:large_face_list_id, face_ids:face_ids, max_num_of_candidates_returned:max_num_of_candidates_returned, mode:mode, custom_headers:custom_headers).value!
    end

    #
    # Given query face's faceId, to search the similar-looking faces from a faceId
    # array, a face list or a large face list. faceId array contains the faces
    # created by [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236),
    # which will expire 24 hours after creation. A "faceListId" is created by
    # [FaceList -
    # Create](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524b)
    # containing persistedFaceIds that will not expire. And a "largeFaceListId" is
    # created by [LargeFaceList -
    # Create](/docs/services/563879b61984550e40cbbe8d/operations/5a157b68d2de3616c086f2cc)
    # containing persistedFaceIds that will also not expire. Depending on the input
    # the returned similar faces list contains faceIds or persistedFaceIds ranked
    # by similarity.
    # <br/>Find similar has two working modes, "matchPerson" and "matchFace".
    # "matchPerson" is the default mode that it tries to find faces of the same
    # person as possible by using internal same-person thresholds. It is useful to
    # find a known person's other photos. Note that an empty list will be returned
    # if no faces pass the internal thresholds. "matchFace" mode ignores
    # same-person thresholds and returns ranked similar faces anyway, even the
    # similarity is low. It can be used in the cases like searching
    # celebrity-looking faces.
    # <br/>The 'recognitionModel' associated with the query face's faceId should be
    # the same as the 'recognitionModel' used by the target faceId array, face list
    # or large face list.
    #
    #
    # @param face_id FaceId of the query face. User needs to call Face - Detect
    # first to get a valid faceId. Note that this faceId is not persisted and will
    # expire 24 hours after the detection call
    # @param face_list_id [String] An existing user-specified unique candidate face
    # list, created in Face List - Create a Face List. Face list contains a set of
    # persistedFaceIds which are persisted and will never expire. Parameter
    # faceListId, largeFaceListId and faceIds should not be provided at the same
    # time.
    # @param large_face_list_id [String] An existing user-specified unique
    # candidate large face list, created in LargeFaceList - Create. Large face list
    # contains a set of persistedFaceIds which are persisted and will never expire.
    # Parameter faceListId, largeFaceListId and faceIds should not be provided at
    # the same time.
    # @param face_ids An array of candidate faceIds. All of them are created by
    # Face - Detect and the faceIds will expire 24 hours after the detection call.
    # The number of faceIds is limited to 1000. Parameter faceListId,
    # largeFaceListId and faceIds should not be provided at the same time.
    # @param max_num_of_candidates_returned [Integer] The number of top similar
    # faces returned. The valid range is [1, 1000].
    # @param mode [FindSimilarMatchMode] Similar face searching mode. It can be
    # "matchPerson" or "matchFace". Possible values include: 'matchPerson',
    # 'matchFace'
    # @param [Hash{String => String}] A hash of custom headers that will be added
    # to the HTTP request.
    #
    # @return [Concurrent::Promise] Promise object which holds the HTTP response.
    #
    def find_similar_async(face_id, face_list_id:nil, large_face_list_id:nil, face_ids:nil, max_num_of_candidates_returned:20, mode:nil, custom_headers:nil)
      fail ArgumentError, '@client.endpoint is nil' if @client.endpoint.nil?
      fail ArgumentError, 'face_id is nil' if face_id.nil?
      fail ArgumentError, "'face_list_id' should satisfy the constraint - 'MaxLength': '64'" if !face_list_id.nil? && face_list_id.length > 64
      fail ArgumentError, "'face_list_id' should satisfy the constraint - 'Pattern': '^[a-z0-9-_]+$'" if !face_list_id.nil? && face_list_id.match(Regexp.new('^^[a-z0-9-_]+$$')).nil?
      fail ArgumentError, "'large_face_list_id' should satisfy the constraint - 'MaxLength': '64'" if !large_face_list_id.nil? && large_face_list_id.length > 64
      fail ArgumentError, "'large_face_list_id' should satisfy the constraint - 'Pattern': '^[a-z0-9-_]+$'" if !large_face_list_id.nil? && large_face_list_id.match(Regexp.new('^^[a-z0-9-_]+$$')).nil?
      fail ArgumentError, "'face_ids' should satisfy the constraint - 'MaxItems': '1000'" if !face_ids.nil? && face_ids.length > 1000
      fail ArgumentError, "'max_num_of_candidates_returned' should satisfy the constraint - 'InclusiveMaximum': '1000'" if !max_num_of_candidates_returned.nil? && max_num_of_candidates_returned > 1000
      fail ArgumentError, "'max_num_of_candidates_returned' should satisfy the constraint - 'InclusiveMinimum': '1'" if !max_num_of_candidates_returned.nil? && max_num_of_candidates_returned < 1

      body = FindSimilarRequest.new
      unless face_id.nil? && face_list_id.nil? && large_face_list_id.nil? && face_ids.nil? && max_num_of_candidates_returned.nil? && mode.nil?
        body.face_id = face_id
        body.face_list_id = face_list_id
        body.large_face_list_id = large_face_list_id
        body.face_ids = face_ids
        body.max_num_of_candidates_returned = max_num_of_candidates_returned
        body.mode = mode
      end

      request_headers = {}
      request_headers['Content-Type'] = 'application/json; charset=utf-8'

      # Set Headers
      request_headers['x-ms-client-request-id'] = SecureRandom.uuid
      request_headers['accept-language'] = @client.accept_language unless @client.accept_language.nil?

      # Serialize Request
      request_mapper = Azure::CognitiveServices::Face::V1_0::Models::FindSimilarRequest.mapper()
      request_content = @client.serialize(request_mapper,  body)
      request_content = request_content != nil ? JSON.generate(request_content, quirks_mode: true) : nil

      path_template = 'findsimilars'

      request_url = @base_url || @client.base_url
    request_url = request_url.gsub('{Endpoint}', @client.endpoint)

      options = {
          middlewares: [[MsRest::RetryPolicyMiddleware, times: 3, retry: 0.02], [:cookie_jar]],
          body: request_content,
          headers: request_headers.merge(custom_headers || {}),
          base_url: request_url
      }
      promise = @client.make_request_async(:post, path_template, options)

      promise = promise.then do |result|
        http_response = result.response
        status_code = http_response.status
        response_content = http_response.body
        unless status_code == 200
          error_model = JSON.load(response_content)
          fail MsRest::HttpOperationError.new(result.request, http_response, error_model)
        end

        result.request_id = http_response['x-ms-request-id'] unless http_response['x-ms-request-id'].nil?
        result.correlation_request_id = http_response['x-ms-correlation-request-id'] unless http_response['x-ms-correlation-request-id'].nil?
        result.client_request_id = http_response['x-ms-client-request-id'] unless http_response['x-ms-client-request-id'].nil?
        # Deserialize Response
        if status_code == 200
          begin
            parsed_response = response_content.to_s.empty? ? nil : JSON.load(response_content)
            result_mapper = {
              client_side_validation: true,
              required: false,
              serialized_name: 'parsed_response',
              type: {
                name: 'Sequence',
                element: {
                    client_side_validation: true,
                    required: false,
                    serialized_name: 'SimilarFaceElementType',
                    type: {
                      name: 'Composite',
                      class_name: 'SimilarFace'
                    }
                }
              }
            }
            result.body = @client.deserialize(result_mapper, parsed_response)
          rescue Exception => e
            fail MsRest::DeserializationError.new('Error occurred in deserializing the response', e.message, e.backtrace, result)
          end
        end

        result
      end

      promise.execute
    end

    #
    # Divide candidate faces into groups based on face similarity.<br />
    # * The output is one or more disjointed face groups and a messyGroup. A face
    # group contains faces that have similar looking, often of the same person.
    # Face groups are ranked by group size, i.e. number of faces. Notice that faces
    # belonging to a same person might be split into several groups in the result.
    # * MessyGroup is a special face group containing faces that cannot find any
    # similar counterpart face from original faces. The messyGroup will not appear
    # in the result if all faces found their counterparts.
    # * Group API needs at least 2 candidate faces and 1000 at most. We suggest to
    # try [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a)
    # when you only have 2 candidate faces.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same.
    #
    #
    # @param face_ids Array of candidate faceId created by Face - Detect. The
    # maximum is 1000 faces
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [GroupResult] operation results.
    #
    def group(face_ids, custom_headers:nil)
      response = group_async(face_ids, custom_headers:custom_headers).value!
      response.body unless response.nil?
    end

    #
    # Divide candidate faces into groups based on face similarity.<br />
    # * The output is one or more disjointed face groups and a messyGroup. A face
    # group contains faces that have similar looking, often of the same person.
    # Face groups are ranked by group size, i.e. number of faces. Notice that faces
    # belonging to a same person might be split into several groups in the result.
    # * MessyGroup is a special face group containing faces that cannot find any
    # similar counterpart face from original faces. The messyGroup will not appear
    # in the result if all faces found their counterparts.
    # * Group API needs at least 2 candidate faces and 1000 at most. We suggest to
    # try [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a)
    # when you only have 2 candidate faces.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same.
    #
    #
    # @param face_ids Array of candidate faceId created by Face - Detect. The
    # maximum is 1000 faces
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [MsRestAzure::AzureOperationResponse] HTTP response information.
    #
    def group_with_http_info(face_ids, custom_headers:nil)
      group_async(face_ids, custom_headers:custom_headers).value!
    end

    #
    # Divide candidate faces into groups based on face similarity.<br />
    # * The output is one or more disjointed face groups and a messyGroup. A face
    # group contains faces that have similar looking, often of the same person.
    # Face groups are ranked by group size, i.e. number of faces. Notice that faces
    # belonging to a same person might be split into several groups in the result.
    # * MessyGroup is a special face group containing faces that cannot find any
    # similar counterpart face from original faces. The messyGroup will not appear
    # in the result if all faces found their counterparts.
    # * Group API needs at least 2 candidate faces and 1000 at most. We suggest to
    # try [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a)
    # when you only have 2 candidate faces.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same.
    #
    #
    # @param face_ids Array of candidate faceId created by Face - Detect. The
    # maximum is 1000 faces
    # @param [Hash{String => String}] A hash of custom headers that will be added
    # to the HTTP request.
    #
    # @return [Concurrent::Promise] Promise object which holds the HTTP response.
    #
    def group_async(face_ids, custom_headers:nil)
      fail ArgumentError, '@client.endpoint is nil' if @client.endpoint.nil?
      fail ArgumentError, 'face_ids is nil' if face_ids.nil?
      fail ArgumentError, "'face_ids' should satisfy the constraint - 'MaxItems': '1000'" if !face_ids.nil? && face_ids.length > 1000

      body = GroupRequest.new
      unless face_ids.nil?
        body.face_ids = face_ids
      end

      request_headers = {}
      request_headers['Content-Type'] = 'application/json; charset=utf-8'

      # Set Headers
      request_headers['x-ms-client-request-id'] = SecureRandom.uuid
      request_headers['accept-language'] = @client.accept_language unless @client.accept_language.nil?

      # Serialize Request
      request_mapper = Azure::CognitiveServices::Face::V1_0::Models::GroupRequest.mapper()
      request_content = @client.serialize(request_mapper,  body)
      request_content = request_content != nil ? JSON.generate(request_content, quirks_mode: true) : nil

      path_template = 'group'

      request_url = @base_url || @client.base_url
    request_url = request_url.gsub('{Endpoint}', @client.endpoint)

      options = {
          middlewares: [[MsRest::RetryPolicyMiddleware, times: 3, retry: 0.02], [:cookie_jar]],
          body: request_content,
          headers: request_headers.merge(custom_headers || {}),
          base_url: request_url
      }
      promise = @client.make_request_async(:post, path_template, options)

      promise = promise.then do |result|
        http_response = result.response
        status_code = http_response.status
        response_content = http_response.body
        unless status_code == 200
          error_model = JSON.load(response_content)
          fail MsRest::HttpOperationError.new(result.request, http_response, error_model)
        end

        result.request_id = http_response['x-ms-request-id'] unless http_response['x-ms-request-id'].nil?
        result.correlation_request_id = http_response['x-ms-correlation-request-id'] unless http_response['x-ms-correlation-request-id'].nil?
        result.client_request_id = http_response['x-ms-client-request-id'] unless http_response['x-ms-client-request-id'].nil?
        # Deserialize Response
        if status_code == 200
          begin
            parsed_response = response_content.to_s.empty? ? nil : JSON.load(response_content)
            result_mapper = Azure::CognitiveServices::Face::V1_0::Models::GroupResult.mapper()
            result.body = @client.deserialize(result_mapper, parsed_response)
          rescue Exception => e
            fail MsRest::DeserializationError.new('Error occurred in deserializing the response', e.message, e.backtrace, result)
          end
        end

        result
      end

      promise.execute
    end

    #
    # 1-to-many identification to find the closest matches of the specific query
    # person face from a person group or large person group.
    # <br/> For each face in the faceIds array, Face Identify will compute
    # similarities between the query face and all the faces in the person group
    # (given by personGroupId) or large person group (given by largePersonGroupId),
    # and return candidate person(s) for that face ranked by similarity confidence.
    # The person group/large person group should be trained to make it ready for
    # identification. See more in [PersonGroup -
    # Train](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249)
    # and [LargePersonGroup -
    # Train](/docs/services/563879b61984550e40cbbe8d/operations/599ae2d16ac60f11b48b5aa4).
    # <br/>
    #
    # Remarks:<br />
    # * The algorithm allows more than one face to be identified independently at
    # the same request, but no more than 10 faces.
    # * Each person in the person group/large person group could have more than one
    # face, but no more than 248 faces.
    # * Higher face image quality means better identification precision. Please
    # consider high-quality faces: frontal, clear, and face size is 200x200 pixels
    # (100 pixels between eyes) or bigger.
    # * Number of candidates returned is restricted by maxNumOfCandidatesReturned
    # and confidenceThreshold. If no person is identified, the returned candidates
    # will be an empty array.
    # * Try [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # when you need to find similar faces from a face list/large face list instead
    # of a person group/large person group.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same as the 'recognitionModel' used by the target person group or large
    # person group.
    #
    #
    # @param face_ids Array of query faces faceIds, created by the Face - Detect.
    # Each of the faces are identified independently. The valid number of faceIds
    # is between [1, 10].
    # @param person_group_id [String] PersonGroupId of the target person group,
    # created by PersonGroup - Create. Parameter personGroupId and
    # largePersonGroupId should not be provided at the same time.
    # @param large_person_group_id [String] LargePersonGroupId of the target large
    # person group, created by LargePersonGroup - Create. Parameter personGroupId
    # and largePersonGroupId should not be provided at the same time.
    # @param max_num_of_candidates_returned [Integer] The range of
    # maxNumOfCandidatesReturned is between 1 and 5 (default is 1).
    # @param confidence_threshold [Float] Confidence threshold of identification,
    # used to judge whether one face belong to one person. The range of
    # confidenceThreshold is [0, 1] (default specified by algorithm).
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [Array] operation results.
    #
    def identify(face_ids, person_group_id:nil, large_person_group_id:nil, max_num_of_candidates_returned:1, confidence_threshold:nil, custom_headers:nil)
      response = identify_async(face_ids, person_group_id:person_group_id, large_person_group_id:large_person_group_id, max_num_of_candidates_returned:max_num_of_candidates_returned, confidence_threshold:confidence_threshold, custom_headers:custom_headers).value!
      response.body unless response.nil?
    end

    #
    # 1-to-many identification to find the closest matches of the specific query
    # person face from a person group or large person group.
    # <br/> For each face in the faceIds array, Face Identify will compute
    # similarities between the query face and all the faces in the person group
    # (given by personGroupId) or large person group (given by largePersonGroupId),
    # and return candidate person(s) for that face ranked by similarity confidence.
    # The person group/large person group should be trained to make it ready for
    # identification. See more in [PersonGroup -
    # Train](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249)
    # and [LargePersonGroup -
    # Train](/docs/services/563879b61984550e40cbbe8d/operations/599ae2d16ac60f11b48b5aa4).
    # <br/>
    #
    # Remarks:<br />
    # * The algorithm allows more than one face to be identified independently at
    # the same request, but no more than 10 faces.
    # * Each person in the person group/large person group could have more than one
    # face, but no more than 248 faces.
    # * Higher face image quality means better identification precision. Please
    # consider high-quality faces: frontal, clear, and face size is 200x200 pixels
    # (100 pixels between eyes) or bigger.
    # * Number of candidates returned is restricted by maxNumOfCandidatesReturned
    # and confidenceThreshold. If no person is identified, the returned candidates
    # will be an empty array.
    # * Try [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # when you need to find similar faces from a face list/large face list instead
    # of a person group/large person group.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same as the 'recognitionModel' used by the target person group or large
    # person group.
    #
    #
    # @param face_ids Array of query faces faceIds, created by the Face - Detect.
    # Each of the faces are identified independently. The valid number of faceIds
    # is between [1, 10].
    # @param person_group_id [String] PersonGroupId of the target person group,
    # created by PersonGroup - Create. Parameter personGroupId and
    # largePersonGroupId should not be provided at the same time.
    # @param large_person_group_id [String] LargePersonGroupId of the target large
    # person group, created by LargePersonGroup - Create. Parameter personGroupId
    # and largePersonGroupId should not be provided at the same time.
    # @param max_num_of_candidates_returned [Integer] The range of
    # maxNumOfCandidatesReturned is between 1 and 5 (default is 1).
    # @param confidence_threshold [Float] Confidence threshold of identification,
    # used to judge whether one face belong to one person. The range of
    # confidenceThreshold is [0, 1] (default specified by algorithm).
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [MsRestAzure::AzureOperationResponse] HTTP response information.
    #
    def identify_with_http_info(face_ids, person_group_id:nil, large_person_group_id:nil, max_num_of_candidates_returned:1, confidence_threshold:nil, custom_headers:nil)
      identify_async(face_ids, person_group_id:person_group_id, large_person_group_id:large_person_group_id, max_num_of_candidates_returned:max_num_of_candidates_returned, confidence_threshold:confidence_threshold, custom_headers:custom_headers).value!
    end

    #
    # 1-to-many identification to find the closest matches of the specific query
    # person face from a person group or large person group.
    # <br/> For each face in the faceIds array, Face Identify will compute
    # similarities between the query face and all the faces in the person group
    # (given by personGroupId) or large person group (given by largePersonGroupId),
    # and return candidate person(s) for that face ranked by similarity confidence.
    # The person group/large person group should be trained to make it ready for
    # identification. See more in [PersonGroup -
    # Train](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249)
    # and [LargePersonGroup -
    # Train](/docs/services/563879b61984550e40cbbe8d/operations/599ae2d16ac60f11b48b5aa4).
    # <br/>
    #
    # Remarks:<br />
    # * The algorithm allows more than one face to be identified independently at
    # the same request, but no more than 10 faces.
    # * Each person in the person group/large person group could have more than one
    # face, but no more than 248 faces.
    # * Higher face image quality means better identification precision. Please
    # consider high-quality faces: frontal, clear, and face size is 200x200 pixels
    # (100 pixels between eyes) or bigger.
    # * Number of candidates returned is restricted by maxNumOfCandidatesReturned
    # and confidenceThreshold. If no person is identified, the returned candidates
    # will be an empty array.
    # * Try [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # when you need to find similar faces from a face list/large face list instead
    # of a person group/large person group.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same as the 'recognitionModel' used by the target person group or large
    # person group.
    #
    #
    # @param face_ids Array of query faces faceIds, created by the Face - Detect.
    # Each of the faces are identified independently. The valid number of faceIds
    # is between [1, 10].
    # @param person_group_id [String] PersonGroupId of the target person group,
    # created by PersonGroup - Create. Parameter personGroupId and
    # largePersonGroupId should not be provided at the same time.
    # @param large_person_group_id [String] LargePersonGroupId of the target large
    # person group, created by LargePersonGroup - Create. Parameter personGroupId
    # and largePersonGroupId should not be provided at the same time.
    # @param max_num_of_candidates_returned [Integer] The range of
    # maxNumOfCandidatesReturned is between 1 and 5 (default is 1).
    # @param confidence_threshold [Float] Confidence threshold of identification,
    # used to judge whether one face belong to one person. The range of
    # confidenceThreshold is [0, 1] (default specified by algorithm).
    # @param [Hash{String => String}] A hash of custom headers that will be added
    # to the HTTP request.
    #
    # @return [Concurrent::Promise] Promise object which holds the HTTP response.
    #
    def identify_async(face_ids, person_group_id:nil, large_person_group_id:nil, max_num_of_candidates_returned:1, confidence_threshold:nil, custom_headers:nil)
      fail ArgumentError, '@client.endpoint is nil' if @client.endpoint.nil?
      fail ArgumentError, 'face_ids is nil' if face_ids.nil?
      fail ArgumentError, "'face_ids' should satisfy the constraint - 'MaxItems': '10'" if !face_ids.nil? && face_ids.length > 10
      fail ArgumentError, "'person_group_id' should satisfy the constraint - 'MaxLength': '64'" if !person_group_id.nil? && person_group_id.length > 64
      fail ArgumentError, "'person_group_id' should satisfy the constraint - 'Pattern': '^[a-z0-9-_]+$'" if !person_group_id.nil? && person_group_id.match(Regexp.new('^^[a-z0-9-_]+$$')).nil?
      fail ArgumentError, "'large_person_group_id' should satisfy the constraint - 'MaxLength': '64'" if !large_person_group_id.nil? && large_person_group_id.length > 64
      fail ArgumentError, "'large_person_group_id' should satisfy the constraint - 'Pattern': '^[a-z0-9-_]+$'" if !large_person_group_id.nil? && large_person_group_id.match(Regexp.new('^^[a-z0-9-_]+$$')).nil?
      fail ArgumentError, "'max_num_of_candidates_returned' should satisfy the constraint - 'InclusiveMaximum': '5'" if !max_num_of_candidates_returned.nil? && max_num_of_candidates_returned > 5
      fail ArgumentError, "'max_num_of_candidates_returned' should satisfy the constraint - 'InclusiveMinimum': '1'" if !max_num_of_candidates_returned.nil? && max_num_of_candidates_returned < 1

      body = Azure::CognitiveServices::Face::V1_0::Models::IdentifyRequest.new
      unless face_ids.nil? && person_group_id.nil? && large_person_group_id.nil? && max_num_of_candidates_returned.nil? && confidence_threshold.nil?
        body.face_ids = face_ids
        body.person_group_id = person_group_id
        body.large_person_group_id = large_person_group_id
        body.max_num_of_candidates_returned = max_num_of_candidates_returned
        body.confidence_threshold = confidence_threshold
      end

      request_headers = {}
      request_headers['Content-Type'] = 'application/json; charset=utf-8'

      # Set Headers
      request_headers['x-ms-client-request-id'] = SecureRandom.uuid
      request_headers['accept-language'] = @client.accept_language unless @client.accept_language.nil?

      # Serialize Request
      request_mapper = Azure::CognitiveServices::Face::V1_0::Models::IdentifyRequest.mapper()
      request_content = @client.serialize(request_mapper,  body)
      request_content = request_content != nil ? JSON.generate(request_content, quirks_mode: true) : nil

      path_template = 'identify'

      request_url = @base_url || @client.base_url
    request_url = request_url.gsub('{Endpoint}', @client.endpoint)

      options = {
          middlewares: [[MsRest::RetryPolicyMiddleware, times: 3, retry: 0.02], [:cookie_jar]],
          body: request_content,
          headers: request_headers.merge(custom_headers || {}),
          base_url: request_url
      }
      promise = @client.make_request_async(:post, path_template, options)

      promise = promise.then do |result|
        http_response = result.response
        status_code = http_response.status
        response_content = http_response.body
        unless status_code == 200
          error_model = JSON.load(response_content)
          fail MsRest::HttpOperationError.new(result.request, http_response, error_model)
        end

        result.request_id = http_response['x-ms-request-id'] unless http_response['x-ms-request-id'].nil?
        result.correlation_request_id = http_response['x-ms-correlation-request-id'] unless http_response['x-ms-correlation-request-id'].nil?
        result.client_request_id = http_response['x-ms-client-request-id'] unless http_response['x-ms-client-request-id'].nil?
        # Deserialize Response
        if status_code == 200
          begin
            parsed_response = response_content.to_s.empty? ? nil : JSON.load(response_content)
            result_mapper = {
              client_side_validation: true,
              required: false,
              serialized_name: 'parsed_response',
              type: {
                name: 'Sequence',
                element: {
                    client_side_validation: true,
                    required: false,
                    serialized_name: 'IdentifyResultElementType',
                    type: {
                      name: 'Composite',
                      class_name: 'IdentifyResult'
                    }
                }
              }
            }
            result.body = @client.deserialize(result_mapper, parsed_response)
          rescue Exception => e
            fail MsRest::DeserializationError.new('Error occurred in deserializing the response', e.message, e.backtrace, result)
          end
        end

        result
      end

      promise.execute
    end

    #
    # Verify whether two faces belong to a same person or whether one face belongs
    # to a person.
    # <br/>
    # Remarks:<br />
    # * Higher face image quality means better identification precision. Please
    # consider high-quality faces: frontal, clear, and face size is 200x200 pixels
    # (100 pixels between eyes) or bigger.
    # * For the scenarios that are sensitive to accuracy please make your own
    # judgment.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same as the 'recognitionModel' used by the target face, person group or
    # large person group.
    #
    #
    # @param face_id1 FaceId of the first face, comes from Face - Detect
    # @param face_id2 FaceId of the second face, comes from Face - Detect
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [VerifyResult] operation results.
    #
    def verify_face_to_face(face_id1, face_id2, custom_headers:nil)
      response = verify_face_to_face_async(face_id1, face_id2, custom_headers:custom_headers).value!
      response.body unless response.nil?
    end

    #
    # Verify whether two faces belong to a same person or whether one face belongs
    # to a person.
    # <br/>
    # Remarks:<br />
    # * Higher face image quality means better identification precision. Please
    # consider high-quality faces: frontal, clear, and face size is 200x200 pixels
    # (100 pixels between eyes) or bigger.
    # * For the scenarios that are sensitive to accuracy please make your own
    # judgment.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same as the 'recognitionModel' used by the target face, person group or
    # large person group.
    #
    #
    # @param face_id1 FaceId of the first face, comes from Face - Detect
    # @param face_id2 FaceId of the second face, comes from Face - Detect
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [MsRestAzure::AzureOperationResponse] HTTP response information.
    #
    def verify_face_to_face_with_http_info(face_id1, face_id2, custom_headers:nil)
      verify_face_to_face_async(face_id1, face_id2, custom_headers:custom_headers).value!
    end

    #
    # Verify whether two faces belong to a same person or whether one face belongs
    # to a person.
    # <br/>
    # Remarks:<br />
    # * Higher face image quality means better identification precision. Please
    # consider high-quality faces: frontal, clear, and face size is 200x200 pixels
    # (100 pixels between eyes) or bigger.
    # * For the scenarios that are sensitive to accuracy please make your own
    # judgment.
    # * The 'recognitionModel' associated with the query faces' faceIds should be
    # the same as the 'recognitionModel' used by the target face, person group or
    # large person group.
    #
    #
    # @param face_id1 FaceId of the first face, comes from Face - Detect
    # @param face_id2 FaceId of the second face, comes from Face - Detect
    # @param [Hash{String => String}] A hash of custom headers that will be added
    # to the HTTP request.
    #
    # @return [Concurrent::Promise] Promise object which holds the HTTP response.
    #
    def verify_face_to_face_async(face_id1, face_id2, custom_headers:nil)
      fail ArgumentError, '@client.endpoint is nil' if @client.endpoint.nil?
      fail ArgumentError, 'face_id1 is nil' if face_id1.nil?
      fail ArgumentError, 'face_id2 is nil' if face_id2.nil?

      body = VerifyFaceToFaceRequest.new
      unless face_id1.nil? && face_id2.nil?
        body.face_id1 = face_id1
        body.face_id2 = face_id2
      end

      request_headers = {}
      request_headers['Content-Type'] = 'application/json; charset=utf-8'

      # Set Headers
      request_headers['x-ms-client-request-id'] = SecureRandom.uuid
      request_headers['accept-language'] = @client.accept_language unless @client.accept_language.nil?

      # Serialize Request
      request_mapper = Azure::CognitiveServices::Face::V1_0::Models::VerifyFaceToFaceRequest.mapper()
      request_content = @client.serialize(request_mapper,  body)
      request_content = request_content != nil ? JSON.generate(request_content, quirks_mode: true) : nil

      path_template = 'verify'

      request_url = @base_url || @client.base_url
    request_url = request_url.gsub('{Endpoint}', @client.endpoint)

      options = {
          middlewares: [[MsRest::RetryPolicyMiddleware, times: 3, retry: 0.02], [:cookie_jar]],
          body: request_content,
          headers: request_headers.merge(custom_headers || {}),
          base_url: request_url
      }
      promise = @client.make_request_async(:post, path_template, options)

      promise = promise.then do |result|
        http_response = result.response
        status_code = http_response.status
        response_content = http_response.body
        unless status_code == 200
          error_model = JSON.load(response_content)
          fail MsRest::HttpOperationError.new(result.request, http_response, error_model)
        end

        result.request_id = http_response['x-ms-request-id'] unless http_response['x-ms-request-id'].nil?
        result.correlation_request_id = http_response['x-ms-correlation-request-id'] unless http_response['x-ms-correlation-request-id'].nil?
        result.client_request_id = http_response['x-ms-client-request-id'] unless http_response['x-ms-client-request-id'].nil?
        # Deserialize Response
        if status_code == 200
          begin
            parsed_response = response_content.to_s.empty? ? nil : JSON.load(response_content)
            result_mapper = Azure::CognitiveServices::Face::V1_0::Models::VerifyResult.mapper()
            result.body = @client.deserialize(result_mapper, parsed_response)
          rescue Exception => e
            fail MsRest::DeserializationError.new('Error occurred in deserializing the response', e.message, e.backtrace, result)
          end
        end

        result
      end

      promise.execute
    end

    #
    # Detect human faces in an image, return face rectangles, and optionally with
    # faceIds, landmarks, and attributes.<br />
    # * No image will be stored. Only the extracted face feature will be stored on
    # server. The faceId is an identifier of the face feature and will be used in
    # [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).
    # The stored face feature(s) will expire and be deleted 24 hours after the
    # original detection call.
    # * Optional parameters include faceId, landmarks, and attributes. Attributes
    # include age, gender, headPose, smile, facialHair, glasses, emotion, hair,
    # makeup, occlusion, accessories, blur, exposure and noise. Some of the results
    # returned for specific attributes may not be highly accurate.
    # * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed
    # image file size is from 1KB to 6MB.
    # * Up to 100 faces can be returned for an image. Faces are ranked by face
    # rectangle size from large to small.
    # * For optimal results when querying [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # ('returnFaceId' is true), please use faces that are: frontal, clear, and with
    # a minimum size of 200x200 pixels (100 pixels between eyes).
    # * The minimum detectable face size is 36x36 pixels in an image no larger than
    # 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will
    # need a proportionally larger minimum face size.
    # * Different 'detectionModel' values can be provided. To use and compare
    # different detection models, please refer to [How to specify a detection
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'detection_01': | The default detection model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # Recommend for near frontal face detection. For scenarios with exceptionally
    # large angle (head-pose) faces, occluded faces or wrong image orientation, the
    # faces in such cases may not be detected. |
    # | 'detection_02': | Detection model released in 2019 May with improved
    # accuracy especially on small, side and blurry faces. |
    #
    # * Different 'recognitionModel' values are provided. If follow-up operations
    # like Verify, Identify, Find Similar are needed, please specify the
    # recognition model with 'recognitionModel' parameter. The default value for
    # 'recognitionModel' is 'recognition_01', if latest model needed, please
    # explicitly specify the model you need in this parameter. Once specified, the
    # detected faceIds will be associated with the specified recognition model.
    # More details, please refer to [How to specify a recognition
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'recognition_01': | The default recognition model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # All those faceIds created before 2019 March are bonded with this recognition
    # model. |
    # | 'recognition_02': | Recognition model released in 2019 March.
    # 'recognition_02' is recommended since its overall accuracy is improved
    # compared with 'recognition_01'. |
    #
    # @param url [String] Publicly reachable URL of an image
    # @param return_face_id [Boolean] A value indicating whether the operation
    # should return faceIds of detected faces.
    # @param return_face_landmarks [Boolean] A value indicating whether the
    # operation should return landmarks of the detected faces.
    # @param return_face_attributes [Array<FaceAttributeType>] Analyze and return
    # the one or more specified face attributes in the comma-separated string like
    # "returnFaceAttributes=age,gender". Supported face attributes include age,
    # gender, headPose, smile, facialHair, glasses and emotion. Note that each face
    # attribute analysis has additional computational and time cost.
    # @param recognition_model [RecognitionModel] Name of recognition model.
    # Recognition model is used when the face features are extracted and associated
    # with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition
    # model name can be provided when performing Face - Detect or (Large)FaceList -
    # Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
    # if latest model needed, please explicitly specify the model you need.
    # Possible values include: 'recognition_01', 'recognition_02'
    # @param return_recognition_model [Boolean] A value indicating whether the
    # operation should return 'recognitionModel' in response.
    # @param detection_model [DetectionModel] Name of detection model. Detection
    # model is used to detect faces in the submitted image. A detection model name
    # can be provided when performing Face - Detect or (Large)FaceList - Add Face
    # or (Large)PersonGroup - Add Face. The default value is 'detection_01', if
    # another model is needed, please explicitly specify it. Possible values
    # include: 'detection_01', 'detection_02'
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [Array] operation results.
    #
    def detect_with_url(url, return_face_id:true, return_face_landmarks:false, return_face_attributes:nil, recognition_model:nil, return_recognition_model:false, detection_model:nil, custom_headers:nil)
      response = detect_with_url_async(url, return_face_id:return_face_id, return_face_landmarks:return_face_landmarks, return_face_attributes:return_face_attributes, recognition_model:recognition_model, return_recognition_model:return_recognition_model, detection_model:detection_model, custom_headers:custom_headers).value!
      response.body unless response.nil?
    end

    #
    # Detect human faces in an image, return face rectangles, and optionally with
    # faceIds, landmarks, and attributes.<br />
    # * No image will be stored. Only the extracted face feature will be stored on
    # server. The faceId is an identifier of the face feature and will be used in
    # [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).
    # The stored face feature(s) will expire and be deleted 24 hours after the
    # original detection call.
    # * Optional parameters include faceId, landmarks, and attributes. Attributes
    # include age, gender, headPose, smile, facialHair, glasses, emotion, hair,
    # makeup, occlusion, accessories, blur, exposure and noise. Some of the results
    # returned for specific attributes may not be highly accurate.
    # * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed
    # image file size is from 1KB to 6MB.
    # * Up to 100 faces can be returned for an image. Faces are ranked by face
    # rectangle size from large to small.
    # * For optimal results when querying [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # ('returnFaceId' is true), please use faces that are: frontal, clear, and with
    # a minimum size of 200x200 pixels (100 pixels between eyes).
    # * The minimum detectable face size is 36x36 pixels in an image no larger than
    # 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will
    # need a proportionally larger minimum face size.
    # * Different 'detectionModel' values can be provided. To use and compare
    # different detection models, please refer to [How to specify a detection
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'detection_01': | The default detection model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # Recommend for near frontal face detection. For scenarios with exceptionally
    # large angle (head-pose) faces, occluded faces or wrong image orientation, the
    # faces in such cases may not be detected. |
    # | 'detection_02': | Detection model released in 2019 May with improved
    # accuracy especially on small, side and blurry faces. |
    #
    # * Different 'recognitionModel' values are provided. If follow-up operations
    # like Verify, Identify, Find Similar are needed, please specify the
    # recognition model with 'recognitionModel' parameter. The default value for
    # 'recognitionModel' is 'recognition_01', if latest model needed, please
    # explicitly specify the model you need in this parameter. Once specified, the
    # detected faceIds will be associated with the specified recognition model.
    # More details, please refer to [How to specify a recognition
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'recognition_01': | The default recognition model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # All those faceIds created before 2019 March are bonded with this recognition
    # model. |
    # | 'recognition_02': | Recognition model released in 2019 March.
    # 'recognition_02' is recommended since its overall accuracy is improved
    # compared with 'recognition_01'. |
    #
    # @param url [String] Publicly reachable URL of an image
    # @param return_face_id [Boolean] A value indicating whether the operation
    # should return faceIds of detected faces.
    # @param return_face_landmarks [Boolean] A value indicating whether the
    # operation should return landmarks of the detected faces.
    # @param return_face_attributes [Array<FaceAttributeType>] Analyze and return
    # the one or more specified face attributes in the comma-separated string like
    # "returnFaceAttributes=age,gender". Supported face attributes include age,
    # gender, headPose, smile, facialHair, glasses and emotion. Note that each face
    # attribute analysis has additional computational and time cost.
    # @param recognition_model [RecognitionModel] Name of recognition model.
    # Recognition model is used when the face features are extracted and associated
    # with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition
    # model name can be provided when performing Face - Detect or (Large)FaceList -
    # Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
    # if latest model needed, please explicitly specify the model you need.
    # Possible values include: 'recognition_01', 'recognition_02'
    # @param return_recognition_model [Boolean] A value indicating whether the
    # operation should return 'recognitionModel' in response.
    # @param detection_model [DetectionModel] Name of detection model. Detection
    # model is used to detect faces in the submitted image. A detection model name
    # can be provided when performing Face - Detect or (Large)FaceList - Add Face
    # or (Large)PersonGroup - Add Face. The default value is 'detection_01', if
    # another model is needed, please explicitly specify it. Possible values
    # include: 'detection_01', 'detection_02'
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [MsRestAzure::AzureOperationResponse] HTTP response information.
    #
    def detect_with_url_with_http_info(url, return_face_id:true, return_face_landmarks:false, return_face_attributes:nil, recognition_model:nil, return_recognition_model:false, detection_model:nil, custom_headers:nil)
      detect_with_url_async(url, return_face_id:return_face_id, return_face_landmarks:return_face_landmarks, return_face_attributes:return_face_attributes, recognition_model:recognition_model, return_recognition_model:return_recognition_model, detection_model:detection_model, custom_headers:custom_headers).value!
    end

    #
    # Detect human faces in an image, return face rectangles, and optionally with
    # faceIds, landmarks, and attributes.<br />
    # * No image will be stored. Only the extracted face feature will be stored on
    # server. The faceId is an identifier of the face feature and will be used in
    # [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).
    # The stored face feature(s) will expire and be deleted 24 hours after the
    # original detection call.
    # * Optional parameters include faceId, landmarks, and attributes. Attributes
    # include age, gender, headPose, smile, facialHair, glasses, emotion, hair,
    # makeup, occlusion, accessories, blur, exposure and noise. Some of the results
    # returned for specific attributes may not be highly accurate.
    # * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed
    # image file size is from 1KB to 6MB.
    # * Up to 100 faces can be returned for an image. Faces are ranked by face
    # rectangle size from large to small.
    # * For optimal results when querying [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # ('returnFaceId' is true), please use faces that are: frontal, clear, and with
    # a minimum size of 200x200 pixels (100 pixels between eyes).
    # * The minimum detectable face size is 36x36 pixels in an image no larger than
    # 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will
    # need a proportionally larger minimum face size.
    # * Different 'detectionModel' values can be provided. To use and compare
    # different detection models, please refer to [How to specify a detection
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'detection_01': | The default detection model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # Recommend for near frontal face detection. For scenarios with exceptionally
    # large angle (head-pose) faces, occluded faces or wrong image orientation, the
    # faces in such cases may not be detected. |
    # | 'detection_02': | Detection model released in 2019 May with improved
    # accuracy especially on small, side and blurry faces. |
    #
    # * Different 'recognitionModel' values are provided. If follow-up operations
    # like Verify, Identify, Find Similar are needed, please specify the
    # recognition model with 'recognitionModel' parameter. The default value for
    # 'recognitionModel' is 'recognition_01', if latest model needed, please
    # explicitly specify the model you need in this parameter. Once specified, the
    # detected faceIds will be associated with the specified recognition model.
    # More details, please refer to [How to specify a recognition
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'recognition_01': | The default recognition model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # All those faceIds created before 2019 March are bonded with this recognition
    # model. |
    # | 'recognition_02': | Recognition model released in 2019 March.
    # 'recognition_02' is recommended since its overall accuracy is improved
    # compared with 'recognition_01'. |
    #
    # @param url [String] Publicly reachable URL of an image
    # @param return_face_id [Boolean] A value indicating whether the operation
    # should return faceIds of detected faces.
    # @param return_face_landmarks [Boolean] A value indicating whether the
    # operation should return landmarks of the detected faces.
    # @param return_face_attributes [Array<FaceAttributeType>] Analyze and return
    # the one or more specified face attributes in the comma-separated string like
    # "returnFaceAttributes=age,gender". Supported face attributes include age,
    # gender, headPose, smile, facialHair, glasses and emotion. Note that each face
    # attribute analysis has additional computational and time cost.
    # @param recognition_model [RecognitionModel] Name of recognition model.
    # Recognition model is used when the face features are extracted and associated
    # with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition
    # model name can be provided when performing Face - Detect or (Large)FaceList -
    # Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
    # if latest model needed, please explicitly specify the model you need.
    # Possible values include: 'recognition_01', 'recognition_02'
    # @param return_recognition_model [Boolean] A value indicating whether the
    # operation should return 'recognitionModel' in response.
    # @param detection_model [DetectionModel] Name of detection model. Detection
    # model is used to detect faces in the submitted image. A detection model name
    # can be provided when performing Face - Detect or (Large)FaceList - Add Face
    # or (Large)PersonGroup - Add Face. The default value is 'detection_01', if
    # another model is needed, please explicitly specify it. Possible values
    # include: 'detection_01', 'detection_02'
    # @param [Hash{String => String}] A hash of custom headers that will be added
    # to the HTTP request.
    #
    # @return [Concurrent::Promise] Promise object which holds the HTTP response.
    #
    def detect_with_url_async(url, return_face_id:true, return_face_landmarks:false, return_face_attributes:nil, recognition_model:nil, return_recognition_model:false, detection_model:nil, custom_headers:nil)
      fail ArgumentError, '@client.endpoint is nil' if @client.endpoint.nil?
      fail ArgumentError, 'url is nil' if url.nil?

      image_url = ImageUrl.new
      unless url.nil?
        image_url.url = url
      end

      request_headers = {}
      request_headers['Content-Type'] = 'application/json; charset=utf-8'

      # Set Headers
      request_headers['x-ms-client-request-id'] = SecureRandom.uuid
      request_headers['accept-language'] = @client.accept_language unless @client.accept_language.nil?

      # Serialize Request
      request_mapper = Azure::CognitiveServices::Face::V1_0::Models::ImageUrl.mapper()
      request_content = @client.serialize(request_mapper,  image_url)
      request_content = request_content != nil ? JSON.generate(request_content, quirks_mode: true) : nil

      path_template = 'detect'

      request_url = @base_url || @client.base_url
    request_url = request_url.gsub('{Endpoint}', @client.endpoint)

      options = {
          middlewares: [[MsRest::RetryPolicyMiddleware, times: 3, retry: 0.02], [:cookie_jar]],
          query_params: {'returnFaceId' => return_face_id,'returnFaceLandmarks' => return_face_landmarks,'returnFaceAttributes' => return_face_attributes.nil? ? nil : return_face_attributes.join(','),'recognitionModel' => recognition_model,'returnRecognitionModel' => return_recognition_model,'detectionModel' => detection_model},
          body: request_content,
          headers: request_headers.merge(custom_headers || {}),
          base_url: request_url
      }
      promise = @client.make_request_async(:post, path_template, options)

      promise = promise.then do |result|
        http_response = result.response
        status_code = http_response.status
        response_content = http_response.body
        unless status_code == 200
          error_model = JSON.load(response_content)
          fail MsRest::HttpOperationError.new(result.request, http_response, error_model)
        end

        result.request_id = http_response['x-ms-request-id'] unless http_response['x-ms-request-id'].nil?
        result.correlation_request_id = http_response['x-ms-correlation-request-id'] unless http_response['x-ms-correlation-request-id'].nil?
        result.client_request_id = http_response['x-ms-client-request-id'] unless http_response['x-ms-client-request-id'].nil?
        # Deserialize Response
        if status_code == 200
          begin
            parsed_response = response_content.to_s.empty? ? nil : JSON.load(response_content)
            result_mapper = {
              client_side_validation: true,
              required: false,
              serialized_name: 'parsed_response',
              type: {
                name: 'Sequence',
                element: {
                    client_side_validation: true,
                    required: false,
                    serialized_name: 'DetectedFaceElementType',
                    type: {
                      name: 'Composite',
                      class_name: 'DetectedFace'
                    }
                }
              }
            }
            result.body = @client.deserialize(result_mapper, parsed_response)
          rescue Exception => e
            fail MsRest::DeserializationError.new('Error occurred in deserializing the response', e.message, e.backtrace, result)
          end
        end

        result
      end

      promise.execute
    end

    #
    # Verify whether two faces belong to a same person. Compares a face Id with a
    # Person Id
    #
    # @param face_id FaceId of the face, comes from Face - Detect
    # @param person_id Specify a certain person in a person group or a large person
    # group. personId is created in PersonGroup Person - Create or LargePersonGroup
    # Person - Create.
    # @param person_group_id [String] Using existing personGroupId and personId for
    # fast loading a specified person. personGroupId is created in PersonGroup -
    # Create. Parameter personGroupId and largePersonGroupId should not be provided
    # at the same time.
    # @param large_person_group_id [String] Using existing largePersonGroupId and
    # personId for fast loading a specified person. largePersonGroupId is created
    # in LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId
    # should not be provided at the same time.
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [VerifyResult] operation results.
    #
    def verify_face_to_person(face_id, person_id, person_group_id:nil, large_person_group_id:nil, custom_headers:nil)
      response = verify_face_to_person_async(face_id, person_id, person_group_id:person_group_id, large_person_group_id:large_person_group_id, custom_headers:custom_headers).value!
      response.body unless response.nil?
    end

    #
    # Verify whether two faces belong to a same person. Compares a face Id with a
    # Person Id
    #
    # @param face_id FaceId of the face, comes from Face - Detect
    # @param person_id Specify a certain person in a person group or a large person
    # group. personId is created in PersonGroup Person - Create or LargePersonGroup
    # Person - Create.
    # @param person_group_id [String] Using existing personGroupId and personId for
    # fast loading a specified person. personGroupId is created in PersonGroup -
    # Create. Parameter personGroupId and largePersonGroupId should not be provided
    # at the same time.
    # @param large_person_group_id [String] Using existing largePersonGroupId and
    # personId for fast loading a specified person. largePersonGroupId is created
    # in LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId
    # should not be provided at the same time.
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [MsRestAzure::AzureOperationResponse] HTTP response information.
    #
    def verify_face_to_person_with_http_info(face_id, person_id, person_group_id:nil, large_person_group_id:nil, custom_headers:nil)
      verify_face_to_person_async(face_id, person_id, person_group_id:person_group_id, large_person_group_id:large_person_group_id, custom_headers:custom_headers).value!
    end

    #
    # Verify whether two faces belong to a same person. Compares a face Id with a
    # Person Id
    #
    # @param face_id FaceId of the face, comes from Face - Detect
    # @param person_id Specify a certain person in a person group or a large person
    # group. personId is created in PersonGroup Person - Create or LargePersonGroup
    # Person - Create.
    # @param person_group_id [String] Using existing personGroupId and personId for
    # fast loading a specified person. personGroupId is created in PersonGroup -
    # Create. Parameter personGroupId and largePersonGroupId should not be provided
    # at the same time.
    # @param large_person_group_id [String] Using existing largePersonGroupId and
    # personId for fast loading a specified person. largePersonGroupId is created
    # in LargePersonGroup - Create. Parameter personGroupId and largePersonGroupId
    # should not be provided at the same time.
    # @param [Hash{String => String}] A hash of custom headers that will be added
    # to the HTTP request.
    #
    # @return [Concurrent::Promise] Promise object which holds the HTTP response.
    #
    def verify_face_to_person_async(face_id, person_id, person_group_id:nil, large_person_group_id:nil, custom_headers:nil)
      fail ArgumentError, '@client.endpoint is nil' if @client.endpoint.nil?
      fail ArgumentError, 'face_id is nil' if face_id.nil?
      fail ArgumentError, "'person_group_id' should satisfy the constraint - 'MaxLength': '64'" if !person_group_id.nil? && person_group_id.length > 64
      fail ArgumentError, "'person_group_id' should satisfy the constraint - 'Pattern': '^[a-z0-9-_]+$'" if !person_group_id.nil? && person_group_id.match(Regexp.new('^^[a-z0-9-_]+$$')).nil?
      fail ArgumentError, "'large_person_group_id' should satisfy the constraint - 'MaxLength': '64'" if !large_person_group_id.nil? && large_person_group_id.length > 64
      fail ArgumentError, "'large_person_group_id' should satisfy the constraint - 'Pattern': '^[a-z0-9-_]+$'" if !large_person_group_id.nil? && large_person_group_id.match(Regexp.new('^^[a-z0-9-_]+$$')).nil?
      fail ArgumentError, 'person_id is nil' if person_id.nil?

      body = VerifyFaceToPersonRequest.new
      unless face_id.nil? && person_group_id.nil? && large_person_group_id.nil? && person_id.nil?
        body.face_id = face_id
        body.person_group_id = person_group_id
        body.large_person_group_id = large_person_group_id
        body.person_id = person_id
      end

      request_headers = {}
      request_headers['Content-Type'] = 'application/json; charset=utf-8'

      # Set Headers
      request_headers['x-ms-client-request-id'] = SecureRandom.uuid
      request_headers['accept-language'] = @client.accept_language unless @client.accept_language.nil?

      # Serialize Request
      request_mapper = Azure::CognitiveServices::Face::V1_0::Models::VerifyFaceToPersonRequest.mapper()
      request_content = @client.serialize(request_mapper,  body)
      request_content = request_content != nil ? JSON.generate(request_content, quirks_mode: true) : nil

      path_template = 'verify'

      request_url = @base_url || @client.base_url
    request_url = request_url.gsub('{Endpoint}', @client.endpoint)

      options = {
          middlewares: [[MsRest::RetryPolicyMiddleware, times: 3, retry: 0.02], [:cookie_jar]],
          body: request_content,
          headers: request_headers.merge(custom_headers || {}),
          base_url: request_url
      }
      promise = @client.make_request_async(:post, path_template, options)

      promise = promise.then do |result|
        http_response = result.response
        status_code = http_response.status
        response_content = http_response.body
        unless status_code == 200
          error_model = JSON.load(response_content)
          fail MsRest::HttpOperationError.new(result.request, http_response, error_model)
        end

        result.request_id = http_response['x-ms-request-id'] unless http_response['x-ms-request-id'].nil?
        result.correlation_request_id = http_response['x-ms-correlation-request-id'] unless http_response['x-ms-correlation-request-id'].nil?
        result.client_request_id = http_response['x-ms-client-request-id'] unless http_response['x-ms-client-request-id'].nil?
        # Deserialize Response
        if status_code == 200
          begin
            parsed_response = response_content.to_s.empty? ? nil : JSON.load(response_content)
            result_mapper = Azure::CognitiveServices::Face::V1_0::Models::VerifyResult.mapper()
            result.body = @client.deserialize(result_mapper, parsed_response)
          rescue Exception => e
            fail MsRest::DeserializationError.new('Error occurred in deserializing the response', e.message, e.backtrace, result)
          end
        end

        result
      end

      promise.execute
    end

    #
    # Detect human faces in an image, return face rectangles, and optionally with
    # faceIds, landmarks, and attributes.<br />
    # * No image will be stored. Only the extracted face feature will be stored on
    # server. The faceId is an identifier of the face feature and will be used in
    # [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).
    # The stored face feature(s) will expire and be deleted 24 hours after the
    # original detection call.
    # * Optional parameters include faceId, landmarks, and attributes. Attributes
    # include age, gender, headPose, smile, facialHair, glasses, emotion, hair,
    # makeup, occlusion, accessories, blur, exposure and noise. Some of the results
    # returned for specific attributes may not be highly accurate.
    # * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed
    # image file size is from 1KB to 6MB.
    # * Up to 100 faces can be returned for an image. Faces are ranked by face
    # rectangle size from large to small.
    # * For optimal results when querying [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # ('returnFaceId' is true), please use faces that are: frontal, clear, and with
    # a minimum size of 200x200 pixels (100 pixels between eyes).
    # * The minimum detectable face size is 36x36 pixels in an image no larger than
    # 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will
    # need a proportionally larger minimum face size.
    # * Different 'detectionModel' values can be provided. To use and compare
    # different detection models, please refer to [How to specify a detection
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'detection_01': | The default detection model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # Recommend for near frontal face detection. For scenarios with exceptionally
    # large angle (head-pose) faces, occluded faces or wrong image orientation, the
    # faces in such cases may not be detected. |
    # | 'detection_02': | Detection model released in 2019 May with improved
    # accuracy especially on small, side and blurry faces. |
    #
    # * Different 'recognitionModel' values are provided. If follow-up operations
    # like Verify, Identify, Find Similar are needed, please specify the
    # recognition model with 'recognitionModel' parameter. The default value for
    # 'recognitionModel' is 'recognition_01', if latest model needed, please
    # explicitly specify the model you need in this parameter. Once specified, the
    # detected faceIds will be associated with the specified recognition model.
    # More details, please refer to [How to specify a recognition
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'recognition_01': | The default recognition model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # All those faceIds created before 2019 March are bonded with this recognition
    # model. |
    # | 'recognition_02': | Recognition model released in 2019 March.
    # 'recognition_02' is recommended since its overall accuracy is improved
    # compared with 'recognition_01'. |
    #
    # @param image An image stream.
    # @param return_face_id [Boolean] A value indicating whether the operation
    # should return faceIds of detected faces.
    # @param return_face_landmarks [Boolean] A value indicating whether the
    # operation should return landmarks of the detected faces.
    # @param return_face_attributes [Array<FaceAttributeType>] Analyze and return
    # the one or more specified face attributes in the comma-separated string like
    # "returnFaceAttributes=age,gender". Supported face attributes include age,
    # gender, headPose, smile, facialHair, glasses and emotion. Note that each face
    # attribute analysis has additional computational and time cost.
    # @param recognition_model [RecognitionModel] Name of recognition model.
    # Recognition model is used when the face features are extracted and associated
    # with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition
    # model name can be provided when performing Face - Detect or (Large)FaceList -
    # Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
    # if latest model needed, please explicitly specify the model you need.
    # Possible values include: 'recognition_01', 'recognition_02'
    # @param return_recognition_model [Boolean] A value indicating whether the
    # operation should return 'recognitionModel' in response.
    # @param detection_model [DetectionModel] Name of detection model. Detection
    # model is used to detect faces in the submitted image. A detection model name
    # can be provided when performing Face - Detect or (Large)FaceList - Add Face
    # or (Large)PersonGroup - Add Face. The default value is 'detection_01', if
    # another model is needed, please explicitly specify it. Possible values
    # include: 'detection_01', 'detection_02'
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [Array] operation results.
    #
    def detect_with_stream(image, return_face_id:true, return_face_landmarks:false, return_face_attributes:nil, recognition_model:nil, return_recognition_model:false, detection_model:nil, custom_headers:nil)
      response = detect_with_stream_async(image, return_face_id:return_face_id, return_face_landmarks:return_face_landmarks, return_face_attributes:return_face_attributes, recognition_model:recognition_model, return_recognition_model:return_recognition_model, detection_model:detection_model, custom_headers:custom_headers).value!
      response.body unless response.nil?
    end

    #
    # Detect human faces in an image, return face rectangles, and optionally with
    # faceIds, landmarks, and attributes.<br />
    # * No image will be stored. Only the extracted face feature will be stored on
    # server. The faceId is an identifier of the face feature and will be used in
    # [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).
    # The stored face feature(s) will expire and be deleted 24 hours after the
    # original detection call.
    # * Optional parameters include faceId, landmarks, and attributes. Attributes
    # include age, gender, headPose, smile, facialHair, glasses, emotion, hair,
    # makeup, occlusion, accessories, blur, exposure and noise. Some of the results
    # returned for specific attributes may not be highly accurate.
    # * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed
    # image file size is from 1KB to 6MB.
    # * Up to 100 faces can be returned for an image. Faces are ranked by face
    # rectangle size from large to small.
    # * For optimal results when querying [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # ('returnFaceId' is true), please use faces that are: frontal, clear, and with
    # a minimum size of 200x200 pixels (100 pixels between eyes).
    # * The minimum detectable face size is 36x36 pixels in an image no larger than
    # 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will
    # need a proportionally larger minimum face size.
    # * Different 'detectionModel' values can be provided. To use and compare
    # different detection models, please refer to [How to specify a detection
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'detection_01': | The default detection model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # Recommend for near frontal face detection. For scenarios with exceptionally
    # large angle (head-pose) faces, occluded faces or wrong image orientation, the
    # faces in such cases may not be detected. |
    # | 'detection_02': | Detection model released in 2019 May with improved
    # accuracy especially on small, side and blurry faces. |
    #
    # * Different 'recognitionModel' values are provided. If follow-up operations
    # like Verify, Identify, Find Similar are needed, please specify the
    # recognition model with 'recognitionModel' parameter. The default value for
    # 'recognitionModel' is 'recognition_01', if latest model needed, please
    # explicitly specify the model you need in this parameter. Once specified, the
    # detected faceIds will be associated with the specified recognition model.
    # More details, please refer to [How to specify a recognition
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'recognition_01': | The default recognition model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # All those faceIds created before 2019 March are bonded with this recognition
    # model. |
    # | 'recognition_02': | Recognition model released in 2019 March.
    # 'recognition_02' is recommended since its overall accuracy is improved
    # compared with 'recognition_01'. |
    #
    # @param image An image stream.
    # @param return_face_id [Boolean] A value indicating whether the operation
    # should return faceIds of detected faces.
    # @param return_face_landmarks [Boolean] A value indicating whether the
    # operation should return landmarks of the detected faces.
    # @param return_face_attributes [Array<FaceAttributeType>] Analyze and return
    # the one or more specified face attributes in the comma-separated string like
    # "returnFaceAttributes=age,gender". Supported face attributes include age,
    # gender, headPose, smile, facialHair, glasses and emotion. Note that each face
    # attribute analysis has additional computational and time cost.
    # @param recognition_model [RecognitionModel] Name of recognition model.
    # Recognition model is used when the face features are extracted and associated
    # with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition
    # model name can be provided when performing Face - Detect or (Large)FaceList -
    # Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
    # if latest model needed, please explicitly specify the model you need.
    # Possible values include: 'recognition_01', 'recognition_02'
    # @param return_recognition_model [Boolean] A value indicating whether the
    # operation should return 'recognitionModel' in response.
    # @param detection_model [DetectionModel] Name of detection model. Detection
    # model is used to detect faces in the submitted image. A detection model name
    # can be provided when performing Face - Detect or (Large)FaceList - Add Face
    # or (Large)PersonGroup - Add Face. The default value is 'detection_01', if
    # another model is needed, please explicitly specify it. Possible values
    # include: 'detection_01', 'detection_02'
    # @param custom_headers [Hash{String => String}] A hash of custom headers that
    # will be added to the HTTP request.
    #
    # @return [MsRestAzure::AzureOperationResponse] HTTP response information.
    #
    def detect_with_stream_with_http_info(image, return_face_id:true, return_face_landmarks:false, return_face_attributes:nil, recognition_model:nil, return_recognition_model:false, detection_model:nil, custom_headers:nil)
      detect_with_stream_async(image, return_face_id:return_face_id, return_face_landmarks:return_face_landmarks, return_face_attributes:return_face_attributes, recognition_model:recognition_model, return_recognition_model:return_recognition_model, detection_model:detection_model, custom_headers:custom_headers).value!
    end

    #
    # Detect human faces in an image, return face rectangles, and optionally with
    # faceIds, landmarks, and attributes.<br />
    # * No image will be stored. Only the extracted face feature will be stored on
    # server. The faceId is an identifier of the face feature and will be used in
    # [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).
    # The stored face feature(s) will expire and be deleted 24 hours after the
    # original detection call.
    # * Optional parameters include faceId, landmarks, and attributes. Attributes
    # include age, gender, headPose, smile, facialHair, glasses, emotion, hair,
    # makeup, occlusion, accessories, blur, exposure and noise. Some of the results
    # returned for specific attributes may not be highly accurate.
    # * JPEG, PNG, GIF (the first frame), and BMP format are supported. The allowed
    # image file size is from 1KB to 6MB.
    # * Up to 100 faces can be returned for an image. Faces are ranked by face
    # rectangle size from large to small.
    # * For optimal results when querying [Face -
    # Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),
    # [Face -
    # Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),
    # and [Face - Find
    # Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)
    # ('returnFaceId' is true), please use faces that are: frontal, clear, and with
    # a minimum size of 200x200 pixels (100 pixels between eyes).
    # * The minimum detectable face size is 36x36 pixels in an image no larger than
    # 1920x1080 pixels. Images with dimensions higher than 1920x1080 pixels will
    # need a proportionally larger minimum face size.
    # * Different 'detectionModel' values can be provided. To use and compare
    # different detection models, please refer to [How to specify a detection
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'detection_01': | The default detection model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # Recommend for near frontal face detection. For scenarios with exceptionally
    # large angle (head-pose) faces, occluded faces or wrong image orientation, the
    # faces in such cases may not be detected. |
    # | 'detection_02': | Detection model released in 2019 May with improved
    # accuracy especially on small, side and blurry faces. |
    #
    # * Different 'recognitionModel' values are provided. If follow-up operations
    # like Verify, Identify, Find Similar are needed, please specify the
    # recognition model with 'recognitionModel' parameter. The default value for
    # 'recognitionModel' is 'recognition_01', if latest model needed, please
    # explicitly specify the model you need in this parameter. Once specified, the
    # detected faceIds will be associated with the specified recognition model.
    # More details, please refer to [How to specify a recognition
    # model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    # | Model | Recommended use-case(s) |
    # | ---------- | -------- |
    # | 'recognition_01': | The default recognition model for [Face -
    # Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).
    # All those faceIds created before 2019 March are bonded with this recognition
    # model. |
    # | 'recognition_02': | Recognition model released in 2019 March.
    # 'recognition_02' is recommended since its overall accuracy is improved
    # compared with 'recognition_01'. |
    #
    # @param image An image stream.
    # @param return_face_id [Boolean] A value indicating whether the operation
    # should return faceIds of detected faces.
    # @param return_face_landmarks [Boolean] A value indicating whether the
    # operation should return landmarks of the detected faces.
    # @param return_face_attributes [Array<FaceAttributeType>] Analyze and return
    # the one or more specified face attributes in the comma-separated string like
    # "returnFaceAttributes=age,gender". Supported face attributes include age,
    # gender, headPose, smile, facialHair, glasses and emotion. Note that each face
    # attribute analysis has additional computational and time cost.
    # @param recognition_model [RecognitionModel] Name of recognition model.
    # Recognition model is used when the face features are extracted and associated
    # with detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition
    # model name can be provided when performing Face - Detect or (Large)FaceList -
    # Create or (Large)PersonGroup - Create. The default value is 'recognition_01',
    # if latest model needed, please explicitly specify the model you need.
    # Possible values include: 'recognition_01', 'recognition_02'
    # @param return_recognition_model [Boolean] A value indicating whether the
    # operation should return 'recognitionModel' in response.
    # @param detection_model [DetectionModel] Name of detection model. Detection
    # model is used to detect faces in the submitted image. A detection model name
    # can be provided when performing Face - Detect or (Large)FaceList - Add Face
    # or (Large)PersonGroup - Add Face. The default value is 'detection_01', if
    # another model is needed, please explicitly specify it. Possible values
    # include: 'detection_01', 'detection_02'
    # @param [Hash{String => String}] A hash of custom headers that will be added
    # to the HTTP request.
    #
    # @return [Concurrent::Promise] Promise object which holds the HTTP response.
    #
    def detect_with_stream_async(image, return_face_id:true, return_face_landmarks:false, return_face_attributes:nil, recognition_model:nil, return_recognition_model:false, detection_model:nil, custom_headers:nil)
      fail ArgumentError, '@client.endpoint is nil' if @client.endpoint.nil?
      fail ArgumentError, 'image is nil' if image.nil?


      request_headers = {}
      request_headers['Content-Type'] = 'application/octet-stream'

      # Set Headers
      request_headers['x-ms-client-request-id'] = SecureRandom.uuid
      request_headers['accept-language'] = @client.accept_language unless @client.accept_language.nil?

      # Serialize Request
      request_mapper = {
        client_side_validation: true,
        required: true,
        serialized_name: 'Image',
        type: {
          name: 'Stream'
        }
      }
      request_content = @client.serialize(request_mapper,  image)

      path_template = 'detect'

      request_url = @base_url || @client.base_url
    request_url = request_url.gsub('{Endpoint}', @client.endpoint)

      options = {
          middlewares: [[MsRest::RetryPolicyMiddleware, times: 3, retry: 0.02], [:cookie_jar]],
          query_params: {'returnFaceId' => return_face_id,'returnFaceLandmarks' => return_face_landmarks,'returnFaceAttributes' => return_face_attributes.nil? ? nil : return_face_attributes.join(','),'recognitionModel' => recognition_model,'returnRecognitionModel' => return_recognition_model,'detectionModel' => detection_model},
          body: request_content,
          headers: request_headers.merge(custom_headers || {}),
          base_url: request_url
      }
      promise = @client.make_request_async(:post, path_template, options)

      promise = promise.then do |result|
        http_response = result.response
        status_code = http_response.status
        response_content = http_response.body
        unless status_code == 200
          error_model = JSON.load(response_content)
          fail MsRest::HttpOperationError.new(result.request, http_response, error_model)
        end

        result.request_id = http_response['x-ms-request-id'] unless http_response['x-ms-request-id'].nil?
        result.correlation_request_id = http_response['x-ms-correlation-request-id'] unless http_response['x-ms-correlation-request-id'].nil?
        result.client_request_id = http_response['x-ms-client-request-id'] unless http_response['x-ms-client-request-id'].nil?
        # Deserialize Response
        if status_code == 200
          begin
            parsed_response = response_content.to_s.empty? ? nil : JSON.load(response_content)
            result_mapper = {
              client_side_validation: true,
              required: false,
              serialized_name: 'parsed_response',
              type: {
                name: 'Sequence',
                element: {
                    client_side_validation: true,
                    required: false,
                    serialized_name: 'DetectedFaceElementType',
                    type: {
                      name: 'Composite',
                      class_name: 'DetectedFace'
                    }
                }
              }
            }
            result.body = @client.deserialize(result_mapper, parsed_response)
          rescue Exception => e
            fail MsRest::DeserializationError.new('Error occurred in deserializing the response', e.message, e.backtrace, result)
          end
        end

        result
      end

      promise.execute
    end

  end
end
