# encoding: utf-8
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.

module Azure::DataFactory::Mgmt::V2018_06_01
  module Models
    #
    # A copy activity sink.
    #
    class CopySink

      include MsRestAzure

      @@discriminatorMap = Hash.new
      @@discriminatorMap["CosmosDbMongoDbApiSink"] = "CosmosDbMongoDbApiSink"
      @@discriminatorMap["SalesforceSink"] = "SalesforceSink"
      @@discriminatorMap["AzureDataExplorerSink"] = "AzureDataExplorerSink"
      @@discriminatorMap["DynamicsSink"] = "DynamicsSink"
      @@discriminatorMap["OdbcSink"] = "OdbcSink"
      @@discriminatorMap["AzureSearchIndexSink"] = "AzureSearchIndexSink"
      @@discriminatorMap["AzureBlobFSSink"] = "AzureBlobFSSink"
      @@discriminatorMap["AzureDataLakeStoreSink"] = "AzureDataLakeStoreSink"
      @@discriminatorMap["OracleSink"] = "OracleSink"
      @@discriminatorMap["SqlDWSink"] = "SqlDWSink"
      @@discriminatorMap["AzureSqlSink"] = "AzureSqlSink"
      @@discriminatorMap["SqlServerSink"] = "SqlServerSink"
      @@discriminatorMap["SqlSink"] = "SqlSink"
      @@discriminatorMap["DocumentDbCollectionSink"] = "DocumentDbCollectionSink"
      @@discriminatorMap["FileSystemSink"] = "FileSystemSink"
      @@discriminatorMap["BlobSink"] = "BlobSink"
      @@discriminatorMap["ParquetSink"] = "ParquetSink"
      @@discriminatorMap["AzureTableSink"] = "AzureTableSink"
      @@discriminatorMap["AzureQueueSink"] = "AzureQueueSink"
      @@discriminatorMap["SapCloudForCustomerSink"] = "SapCloudForCustomerSink"
      @@discriminatorMap["DelimitedTextSink"] = "DelimitedTextSink"

      def initialize
        @type = "CopySink"
      end

      attr_accessor :type

      # @return Unmatched properties from the message are deserialized this
      # collection
      attr_accessor :additional_properties

      # @return Write batch size. Type: integer (or Expression with resultType
      # integer), minimum: 0.
      attr_accessor :write_batch_size

      # @return Write batch timeout. Type: string (or Expression with
      # resultType string), pattern:
      # ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
      attr_accessor :write_batch_timeout

      # @return Sink retry count. Type: integer (or Expression with resultType
      # integer).
      attr_accessor :sink_retry_count

      # @return Sink retry wait. Type: string (or Expression with resultType
      # string), pattern: ((\d+)\.)?(\d\d):(60|([0-5][0-9])):(60|([0-5][0-9])).
      attr_accessor :sink_retry_wait

      # @return The maximum concurrent connection count for the sink data
      # store. Type: integer (or Expression with resultType integer).
      attr_accessor :max_concurrent_connections


      #
      # Mapper for CopySink class as Ruby Hash.
      # This will be used for serialization/deserialization.
      #
      def self.mapper()
        {
          client_side_validation: true,
          required: false,
          serialized_name: 'CopySink',
          type: {
            name: 'Composite',
            polymorphic_discriminator: 'type',
            uber_parent: 'CopySink',
            class_name: 'CopySink',
            model_properties: {
              additional_properties: {
                client_side_validation: true,
                required: false,
                type: {
                  name: 'Dictionary',
                  value: {
                      client_side_validation: true,
                      required: false,
                      serialized_name: 'ObjectElementType',
                      type: {
                        name: 'Object'
                      }
                  }
                }
              },
              write_batch_size: {
                client_side_validation: true,
                required: false,
                serialized_name: 'writeBatchSize',
                type: {
                  name: 'Object'
                }
              },
              write_batch_timeout: {
                client_side_validation: true,
                required: false,
                serialized_name: 'writeBatchTimeout',
                type: {
                  name: 'Object'
                }
              },
              sink_retry_count: {
                client_side_validation: true,
                required: false,
                serialized_name: 'sinkRetryCount',
                type: {
                  name: 'Object'
                }
              },
              sink_retry_wait: {
                client_side_validation: true,
                required: false,
                serialized_name: 'sinkRetryWait',
                type: {
                  name: 'Object'
                }
              },
              max_concurrent_connections: {
                client_side_validation: true,
                required: false,
                serialized_name: 'maxConcurrentConnections',
                type: {
                  name: 'Object'
                }
              }
            }
          }
        }
      end
    end
  end
end
